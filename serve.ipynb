{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import wikipedia\n",
    "from scipy.spatial import distance\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from wikipedia import DisambiguationError\n",
    "tqdm.pandas()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ruw0D2rBIRxP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>link</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Ah shit, here we go again\" Снова летний трип ...</td>\n",
       "      <td>https://pesnihi.com/lyrics/a/alphavite/kubok-m...</td>\n",
       "      <td>Alphavite, Hallowen, KnownAim, MIREKU DJIMA, м...</td>\n",
       "      <td>КУБОК МЦ (7)</td>\n",
       "      <td>[0.4156811535358429, -0.510965883731842, 0.116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"S1\" (feat. РАМШ) — Да, да — Алё, выйдешь? Всп...</td>\n",
       "      <td>https://pesnihi.com/lyrics/1/104/s1.html</td>\n",
       "      <td>104, Saluki, РАМШ</td>\n",
       "      <td>S1</td>\n",
       "      <td>[1.0112338066101074, -0.45509031414985657, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Азино\" семь-семь-семь По-по-поднял бабла (у) ...</td>\n",
       "      <td>https://pesnihi.com/lyrics/v/vitya-ak/azino-tr...</td>\n",
       "      <td>Витя АК</td>\n",
       "      <td>Азино три топора</td>\n",
       "      <td>[-0.05332232639193535, -0.2194392830133438, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Глаз заглядывает за рамки мира сего в иной И ...</td>\n",
       "      <td>https://pesnihi.com/lyrics/n/namelessjulia/pir...</td>\n",
       "      <td>namelessjulia, Найтивыход</td>\n",
       "      <td>Пирамида над Кремлём</td>\n",
       "      <td>[0.0619158111512661, -0.2646079659461975, 0.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"За сином слєді, дорогая\" - шептав мій отєц ум...</td>\n",
       "      <td>https://pesnihi.com/lyrics/h/hamerman-znishhue...</td>\n",
       "      <td>Хамерман Знищує Віруси</td>\n",
       "      <td>Раненое децтво</td>\n",
       "      <td>[0.9022114276885986, -1.0176315307617188, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \"Ah shit, here we go again\" Снова летний трип ...   \n",
       "1  \"S1\" (feat. РАМШ) — Да, да — Алё, выйдешь? Всп...   \n",
       "2  \"Азино\" семь-семь-семь По-по-поднял бабла (у) ...   \n",
       "3  \"Глаз заглядывает за рамки мира сего в иной И ...   \n",
       "4  \"За сином слєді, дорогая\" - шептав мій отєц ум...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://pesnihi.com/lyrics/a/alphavite/kubok-m...   \n",
       "1           https://pesnihi.com/lyrics/1/104/s1.html   \n",
       "2  https://pesnihi.com/lyrics/v/vitya-ak/azino-tr...   \n",
       "3  https://pesnihi.com/lyrics/n/namelessjulia/pir...   \n",
       "4  https://pesnihi.com/lyrics/h/hamerman-znishhue...   \n",
       "\n",
       "                                              artist                 title  \\\n",
       "0  Alphavite, Hallowen, KnownAim, MIREKU DJIMA, м...          КУБОК МЦ (7)   \n",
       "1                                  104, Saluki, РАМШ                    S1   \n",
       "2                                            Витя АК      Азино три топора   \n",
       "3                          namelessjulia, Найтивыход  Пирамида над Кремлём   \n",
       "4                             Хамерман Знищує Віруси        Раненое децтво   \n",
       "\n",
       "                                              embeds  \n",
       "0  [0.4156811535358429, -0.510965883731842, 0.116...  \n",
       "1  [1.0112338066101074, -0.45509031414985657, 0.2...  \n",
       "2  [-0.05332232639193535, -0.2194392830133438, -0...  \n",
       "3  [0.0619158111512661, -0.2646079659461975, 0.41...  \n",
       "4  [0.9022114276885986, -1.0176315307617188, -0.0...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset_with_embeds.csv\", sep=\";\")\n",
    "dataset[\"embeds\"] = dataset[\"embeds\"].apply(lambda x: np.array(list(map(float, x[1:-1].split(\",\")))))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "id": "DcWPrEQcsPPl",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pretrained were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at pretrained and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
       "    (position_embeddings): Embedding(2048, 312)\n",
       "    (token_type_embeddings): Embedding(2, 312)\n",
       "    (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "          (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "          (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "          (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\", cache_dir=None, do_lower_case=True)\n",
    "model = BertModel.from_pretrained(\"pretrained\", cache_dir=None)\n",
    "device=\"cpu\" \n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "j0ELNv60QnZS"
   },
   "outputs": [],
   "source": [
    "def fix_errors(text):\n",
    "  text = text.lower().split(\"?\")[0]\n",
    "  domain = \"https://speller.yandex.net/services/spellservice.json\"\n",
    "  words = text.split()\n",
    "  words = \"+\".join(words)\n",
    "  request = requests.get(domain + \"/checkText?text=\" + words)\n",
    "  if request:\n",
    "    response = [(i[\"word\"], i[\"s\"]) for i in request.json()]\n",
    "    for word, fixes in response:\n",
    "      text = text.replace(word, fixes[0])\n",
    "    return text\n",
    "  return text\n",
    "\n",
    "def convert_to_bert_line(text, tokenizer, max_seq_length=2048):\n",
    "    tokens = \"[CLS] \" + text\n",
    "    tokens = tokenizer(tokens, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    return tokens \n",
    "\n",
    "def process_request(text, n=5):\n",
    "  text = text.lower()\n",
    "  fixed_text = fix_errors(text)\n",
    "  if fixed_text != text:\n",
    "    print(f\"Do you mean: '{fixed_text}'?\")\n",
    "    if input(\"Y/n:\") == \"Y\":\n",
    "      text = fixed_text\n",
    "  tokens = torch.tensor(convert_to_bert_line(text, tokenizer)[\"input_ids\"], dtype=torch.long).reshape(1, -1)\n",
    "  preds = model(tokens.to(device),\n",
    "                attention_mask=(tokens > 0).to(device),\n",
    "                return_dict=False)\n",
    "  request_embeds = preds[0].detach().cpu().numpy().tolist()[0][0]\n",
    "  response = dataset.copy()\n",
    "  response[\"dist\"] = response[\"embeds\"].progress_apply(lambda x: distance.cosine(request_embeds, x))\n",
    "  response = response.sort_values(by=\"dist\").head(n)\n",
    "  return response\n",
    "\n",
    "def print_response(response):\n",
    "    wikipedia.set_lang(\"ru\")\n",
    "    for i in range(response.shape[0]):\n",
    "        row = response.iloc[i]\n",
    "        print(f\"\\nItem #{i + 1}\")\n",
    "        print(f\"Author and title: {row['artist']} - {row['title']}\")\n",
    "        print(f\"Text sample: {row['text'][:200]}\")\n",
    "        wiki_results = wikipedia.search(row['artist'], results=5)\n",
    "        wiki_links = []\n",
    "        for result in wiki_results:\n",
    "          try:\n",
    "            wiki_links.append(wikipedia.page(result).url)\n",
    "          except DisambiguationError:\n",
    "            wiki_links.append(\"Too many options to choose\")\n",
    "        print(\"Wikipedia results:\")\n",
    "        for j in range(len(wiki_links)):\n",
    "            print(f\"#{j + 1} {wiki_results[j]} {wiki_links[j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "OnLZeQr6RgGL"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82924ca774ca43c7b7ac6f32d9a4b6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item #1\n",
      "Author and title: Маугли - Москва\n",
      "Text sample: Москва, Москва, Москва, Москва Москва, Москва, Москва (Москва, Москва, Москва Москва, Москва, Москва) Я расту точно плесень на гороскопе Москвы Душат барышень барашы из карманов и малыши Волоку пресно\n",
      "Wikipedia results:\n",
      "#1 Маугли https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%83%D0%B3%D0%BB%D0%B8\n",
      "#2 Маугли (мультфильм) https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%83%D0%B3%D0%BB%D0%B8_(%D0%BC%D1%83%D0%BB%D1%8C%D1%82%D1%84%D0%B8%D0%BB%D1%8C%D0%BC)\n",
      "#3 Книга джунглей https://ru.wikipedia.org/wiki/%D0%9A%D0%BD%D0%B8%D0%B3%D0%B0_%D0%B4%D0%B6%D1%83%D0%BD%D0%B3%D0%BB%D0%B5%D0%B9\n",
      "#4 Маугли (фильм) https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%83%D0%B3%D0%BB%D0%B8_(%D1%84%D0%B8%D0%BB%D1%8C%D0%BC)\n",
      "#5 Маугли (значения) Too many options to choose\n",
      "\n",
      "Item #2\n",
      "Author and title: Гуф (GUF), Тимати - Москва\n",
      "Text sample: Тимати и ГУФ стоят на самом Высом обзорном этаже Москва-сити. Ща поясню О! Москва, в любое время дня и ночи Москва - здесь ты найдёшь всё, что захочешь Москва сияет яркими огнями Москва, Москва, Москв\n",
      "Wikipedia results:\n",
      "#1 Гуф https://ru.wikipedia.org/wiki/%D0%93%D1%83%D1%84\n",
      "#2 Тимати https://ru.wikipedia.org/wiki/%D0%A2%D0%B8%D0%BC%D0%B0%D1%82%D0%B8\n",
      "#3 Москва (песня Тимати) https://ru.wikipedia.org/wiki/%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D0%B0_(%D0%BF%D0%B5%D1%81%D0%BD%D1%8F_%D0%A2%D0%B8%D0%BC%D0%B0%D1%82%D0%B8)\n",
      "#4 Рем Дигга https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%BC_%D0%94%D0%B8%D0%B3%D0%B3%D0%B0\n",
      "#5 Cadillac (песня) https://ru.wikipedia.org/wiki/Cadillac_(%D0%BF%D0%B5%D1%81%D0%BD%D1%8F)\n",
      "\n",
      "Item #3\n",
      "Author and title: ЛЮБЭ - Эх, Мосвка\n",
      "Text sample: Снова по деревне дождь идет, и пчела жужжит в оконце И трава на цыпочки встает, чтобы раньше всех увидеть солнце Но среди асфальта у моста, я машу вслед облаку рукою Эх, Москва, моя Москва, что же ты \n",
      "Wikipedia results:\n",
      "#1 Любэ https://ru.wikipedia.org/wiki/%D0%9B%D1%8E%D0%B1%D1%8D\n",
      "#2 Расторгуев, Николай Вячеславович https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D1%82%D0%BE%D1%80%D0%B3%D1%83%D0%B5%D0%B2,_%D0%9D%D0%B8%D0%BA%D0%BE%D0%BB%D0%B0%D0%B9_%D0%92%D1%8F%D1%87%D0%B5%D1%81%D0%BB%D0%B0%D0%B2%D0%BE%D0%B2%D0%B8%D1%87\n",
      "#3 Зона Любэ (значения) Too many options to choose\n",
      "#4 Зона Любэ (фильм) https://ru.wikipedia.org/wiki/%D0%97%D0%BE%D0%BD%D0%B0_%D0%9B%D1%8E%D0%B1%D1%8D\n",
      "#5 Конь (песня) https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BD%D1%8C_(%D0%BF%D0%B5%D1%81%D0%BD%D1%8F)\n",
      "\n",
      "Item #4\n",
      "Author and title: Лариса Долина - Москвичка\n",
      "Text sample: Новый день о себе заявил, встало солнышко над океаном Начинается Москва от Курил и конца не видать на Кубани. Над Москвой небо синее, у Москвы имя сильное. Москва - Таганка, Москва - Арбат, Москва - т\n",
      "Wikipedia results:\n",
      "#1 Долина, Лариса Александровна https://ru.wikipedia.org/wiki/%D0%94%D0%BE%D0%BB%D0%B8%D0%BD%D0%B0,_%D0%9B%D0%B0%D1%80%D0%B8%D1%81%D0%B0_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B2%D0%BD%D0%B0\n",
      "#2 Маска (телешоу) https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%81%D0%BA%D0%B0_(%D1%82%D0%B5%D0%BB%D0%B5%D1%88%D0%BE%D1%83)\n",
      "#3 Три белых коня https://ru.wikipedia.org/wiki/%D0%A2%D1%80%D0%B8_%D0%B1%D0%B5%D0%BB%D1%8B%D1%85_%D0%BA%D0%BE%D0%BD%D1%8F\n",
      "#4 Рубальская, Лариса Алексеевна https://ru.wikipedia.org/wiki/%D0%A0%D1%83%D0%B1%D0%B0%D0%BB%D1%8C%D1%81%D0%BA%D0%B0%D1%8F,_%D0%9B%D0%B0%D1%80%D0%B8%D1%81%D0%B0_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B5%D0%B5%D0%B2%D0%BD%D0%B0\n",
      "#5 Резников, Виктор Михайлович https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%B7%D0%BD%D0%B8%D0%BA%D0%BE%D0%B2,_%D0%92%D0%B8%D0%BA%D1%82%D0%BE%D1%80_%D0%9C%D0%B8%D1%85%D0%B0%D0%B9%D0%BB%D0%BE%D0%B2%D0%B8%D1%87\n",
      "\n",
      "Item #5\n",
      "Author and title: Лигалайз - Моя Москва!\n",
      "Text sample: Моя Москва, да мы вернулись Моя Москва, с мелодией для улиц Моя Москва, я твой всегда Моя Москва, Л. Г. и А Я с улицы с названием Оргуновская Где за Останкинскую башню заходит солнце Где мы учились иг\n",
      "Wikipedia results:\n",
      "#1 Лигалайз https://ru.wikipedia.org/wiki/%D0%9B%D0%B8%D0%B3%D0%B0%D0%BB%D0%B0%D0%B9%D0%B7\n",
      "#2 Небо, засыпай https://ru.wikipedia.org/wiki/%D0%9D%D0%B5%D0%B1%D0%BE,_%D0%B7%D0%B0%D1%81%D1%8B%D0%BF%D0%B0%D0%B9\n",
      "#3 Шеff https://ru.wikipedia.org/wiki/%D0%A8%D0%B5ff\n",
      "#4 ALI https://ru.wikipedia.org/wiki/ALI\n",
      "#5 Клуб (телесериал) https://ru.wikipedia.org/wiki/%D0%9A%D0%BB%D1%83%D0%B1_(%D1%82%D0%B5%D0%BB%D0%B5%D1%81%D0%B5%D1%80%D0%B8%D0%B0%D0%BB)\n"
     ]
    }
   ],
   "source": [
    "response = process_request(\"Москва\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
